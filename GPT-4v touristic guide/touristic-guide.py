# Configuration
GPT_4V_ENDPOINT = "your-deployment-endpoint"
GPT_4V_KEY = "your-aoai-key"
VISION_API_ENDPOINT = "your-vision-endpoint"
VISION_API_KEY = "your-vision-key"

import base64
import datetime
import glob
import json
import openai
import os
import requests
import sys
from dotenv import load_dotenv
from io import BytesIO
from PIL import Image
import streamlit as st
from PIL import Image


INDEX_NAME = "aoai-touristic-guide"

system_message = """

You are an expert touristic guide. Given a picture of an artwork or monument, you provide a comprehensive description of it, including the artist's background and the message it wanted to convey. 
The output paragraph will be organized as follow:

1)**Title of the item**: 

2)**Artist name and background**: 

3)**Date of production**:

4)**Item description with historical background**:

At the end of your paragraph, share with the user an *anecdote* about the item, so that it will be easier to remember it in the future.

"""

st.image("cover.jpg", width=500)
st.title('üèõWelcome to your personal touristic guide!üé®')

st.sidebar.title("üèõGPTourism!üé®")
st.sidebar.caption("Made by an [Valentina Alto](https://www.linkedin.com/in/valentina-alto-6a0590148/)")
st.sidebar.info("""
Note: Be aware that the content provided by this application is generated by AI. While we strive to provide accurate and up-to-date information, there may be instances where the AI-generated content might be incorrect, outdated, or incomplete. 
We recommend users to use this information as a guide and to perform personal due diligence to verify the accuracy of the information provided. We are not responsible for any decisions made based on the information provided by this application.
"""
)

# Create a column layout
left_column, right_column = st.columns(2)

left_column.subheader("Caption something you are interested in")
right_column.subheader("Artwork card")


def GPT4V_with_AzureAIVision(encoded_image, prompt):

    # Header
    headers = {"Content-Type": "application/json", 
               "api-key": GPT_4V_KEY}

    # Encoded image
    #base_64_encoded_image = base64.b64encode(open(image_file, "rb").read()).decode(
    #    "ascii")

    # Payload
    json_data = {
        "enhancements": {"ocr": {"enabled": True}, "grounding": {"enabled": True}},
        "dataSources": [
            {
                "type": "AzureComputerVision",
                "endpoint": VISION_API_ENDPOINT,
                "key": VISION_API_KEY,
                "indexName": INDEX_NAME,
            }
        ],
        "messages": [
            {"role": "system", "content": system_message},
            {"role": "user", "content": [prompt, {"image": encoded_image}]},
        ],
        "max_tokens": 4000,
        "temperature": 0.7,
        "top_p": 1,
    }

    # Response
    response = requests.post(
        GPT_4V_ENDPOINT, headers=headers, data=json.dumps(json_data)
    )
    results = json.loads(response.text)
    return results["choices"][0]["message"]["content"]

    


def get_image_as_base64(image_file):
    with open(image_file, "rb") as img_file:
        return base64.b64encode(img_file.read()).decode('ascii')

# In the left column, allow the user to upload an image
uploaded_file = left_column.file_uploader("Choose an image...", type=["jpg", "png", "jpeg"])

# If an image is uploaded, display it and its description
if uploaded_file is not None:
    with open("temp_file", "wb") as f:
        f.write(uploaded_file.getbuffer())
    base64_image = get_image_as_base64("temp_file")
    #st.write(base64_image)
    left_column.image(uploaded_file)
    #st.write(base64_image)
    output = GPT4V_with_AzureAIVision(base64_image, prompt = 'what is it?')
    right_column.write(output)
